{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Homework 6 : Implement random forest in Spark\n",
    "\n",
    "#### Author: Akshat Gaur\n",
    "#### AndrewID: agaur\n",
    "\n",
    "#### Task:\n",
    "\n",
    "You will now create a Spark implementation of the random forest method that you are familiar with. This will help you come to understand how the Spark architecture differs from MapReduce and standard serial computing, particularly with reference to the pipelines API. Spark ML enables large in-memory parallel learning work to be done, and it can be much faster than MapReduce for certain tasks. This assignment will also give you practice using the pipelines API and understand how to construct a meaningful analytic projects in spark."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Create Spark Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.master(\"local\") \\\n",
    "        .appName(\"Random Forest\") \\\n",
    "        .config(\"spark.some.config.option\", \"some-value\") \\\n",
    "        .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Create a schema and assign headers to the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Schema:\n",
      "root\n",
      " |-- Sex: string (nullable = true)\n",
      " |-- Length: double (nullable = true)\n",
      " |-- Diameter: double (nullable = true)\n",
      " |-- Height: double (nullable = true)\n",
      " |-- WholeWeight: double (nullable = true)\n",
      " |-- ShuckedWeight: double (nullable = true)\n",
      " |-- VisceraWeight: double (nullable = true)\n",
      " |-- ShellWeight: double (nullable = true)\n",
      " |-- Rings: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.types import *\n",
    "\n",
    "schema = StructType([StructField('Sex', StringType(), True), StructField('Length', DoubleType(), True), \n",
    "                    StructField('Diameter', DoubleType(), True), StructField('Height', DoubleType(), True),\n",
    "                    StructField(\"WholeWeight\", DoubleType(), True), StructField(\"ShuckedWeight\", DoubleType(), True),\n",
    "                    StructField(\"VisceraWeight\", DoubleType(), True), StructField(\"ShellWeight\", DoubleType(), True),\n",
    "                    StructField(\"Rings\", IntegerType(), True)])\n",
    "\n",
    "df = spark.read.format('com.databricks.spark.csv').load('./abalone.data', header=False, schema=schema)\n",
    "\n",
    "print 'Schema:'\n",
    "df.printSchema()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Transform categorical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+--------+------+-----------+-------------+-------------+-----------+-----+------+-------------+\n",
      "|Sex|Length|Diameter|Height|WholeWeight|ShuckedWeight|VisceraWeight|ShellWeight|Rings|NewSex|   NumericSex|\n",
      "+---+------+--------+------+-----------+-------------+-------------+-----------+-----+------+-------------+\n",
      "|  M| 0.455|   0.365| 0.095|      0.514|       0.2245|        0.101|       0.15|   15|   0.0|(2,[0],[1.0])|\n",
      "|  M|  0.35|   0.265|  0.09|     0.2255|       0.0995|       0.0485|       0.07|    7|   0.0|(2,[0],[1.0])|\n",
      "|  F|  0.53|    0.42| 0.135|      0.677|       0.2565|       0.1415|       0.21|    9|   2.0|    (2,[],[])|\n",
      "|  M|  0.44|   0.365| 0.125|      0.516|       0.2155|        0.114|      0.155|   10|   0.0|(2,[0],[1.0])|\n",
      "|  I|  0.33|   0.255|  0.08|      0.205|       0.0895|       0.0395|      0.055|    7|   1.0|(2,[1],[1.0])|\n",
      "|  I| 0.425|     0.3| 0.095|     0.3515|        0.141|       0.0775|       0.12|    8|   1.0|(2,[1],[1.0])|\n",
      "|  F|  0.53|   0.415|  0.15|     0.7775|        0.237|       0.1415|       0.33|   20|   2.0|    (2,[],[])|\n",
      "|  F| 0.545|   0.425| 0.125|      0.768|        0.294|       0.1495|       0.26|   16|   2.0|    (2,[],[])|\n",
      "|  M| 0.475|    0.37| 0.125|     0.5095|       0.2165|       0.1125|      0.165|    9|   0.0|(2,[0],[1.0])|\n",
      "|  F|  0.55|    0.44|  0.15|     0.8945|       0.3145|        0.151|       0.32|   19|   2.0|    (2,[],[])|\n",
      "|  F| 0.525|    0.38|  0.14|     0.6065|        0.194|       0.1475|       0.21|   14|   2.0|    (2,[],[])|\n",
      "|  M|  0.43|    0.35|  0.11|      0.406|       0.1675|        0.081|      0.135|   10|   0.0|(2,[0],[1.0])|\n",
      "|  M|  0.49|    0.38| 0.135|     0.5415|       0.2175|        0.095|       0.19|   11|   0.0|(2,[0],[1.0])|\n",
      "|  F| 0.535|   0.405| 0.145|     0.6845|       0.2725|        0.171|      0.205|   10|   2.0|    (2,[],[])|\n",
      "|  F|  0.47|   0.355|   0.1|     0.4755|       0.1675|       0.0805|      0.185|   10|   2.0|    (2,[],[])|\n",
      "|  M|   0.5|     0.4|  0.13|     0.6645|        0.258|        0.133|       0.24|   12|   0.0|(2,[0],[1.0])|\n",
      "|  I| 0.355|    0.28| 0.085|     0.2905|        0.095|       0.0395|      0.115|    7|   1.0|(2,[1],[1.0])|\n",
      "|  F|  0.44|    0.34|   0.1|      0.451|        0.188|        0.087|       0.13|   10|   2.0|    (2,[],[])|\n",
      "|  M| 0.365|   0.295|  0.08|     0.2555|        0.097|        0.043|        0.1|    7|   0.0|(2,[0],[1.0])|\n",
      "|  M|  0.45|    0.32|   0.1|      0.381|       0.1705|        0.075|      0.115|    9|   0.0|(2,[0],[1.0])|\n",
      "+---+------+--------+------+-----------+-------------+-------------+-----------+-----+------+-------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import OneHotEncoder, StringIndexer\n",
    "\n",
    "stringIndexer = StringIndexer(inputCol='Sex', outputCol='NewSex')\n",
    "model = stringIndexer.fit(df)\n",
    "indexed = model.transform(df)\n",
    "\n",
    "encoder = OneHotEncoder(inputCol='NewSex', outputCol='NumericSex')\n",
    "encoded = encoder.transform(indexed)\n",
    "encoded.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Print top 10 rows of the final features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------+------+-----------+-------------+-------------+-----------+----------+-------------+\n",
      "|Length|Diameter|Height|WholeWeight|ShuckedWeight|VisceraWeight|ShellWeight|truelabels|   NumericSex|\n",
      "+------+--------+------+-----------+-------------+-------------+-----------+----------+-------------+\n",
      "| 0.455|   0.365| 0.095|      0.514|       0.2245|        0.101|       0.15|        15|(2,[0],[1.0])|\n",
      "|  0.35|   0.265|  0.09|     0.2255|       0.0995|       0.0485|       0.07|         7|(2,[0],[1.0])|\n",
      "|  0.53|    0.42| 0.135|      0.677|       0.2565|       0.1415|       0.21|         9|    (2,[],[])|\n",
      "|  0.44|   0.365| 0.125|      0.516|       0.2155|        0.114|      0.155|        10|(2,[0],[1.0])|\n",
      "|  0.33|   0.255|  0.08|      0.205|       0.0895|       0.0395|      0.055|         7|(2,[1],[1.0])|\n",
      "| 0.425|     0.3| 0.095|     0.3515|        0.141|       0.0775|       0.12|         8|(2,[1],[1.0])|\n",
      "|  0.53|   0.415|  0.15|     0.7775|        0.237|       0.1415|       0.33|        20|    (2,[],[])|\n",
      "| 0.545|   0.425| 0.125|      0.768|        0.294|       0.1495|       0.26|        16|    (2,[],[])|\n",
      "| 0.475|    0.37| 0.125|     0.5095|       0.2165|       0.1125|      0.165|         9|(2,[0],[1.0])|\n",
      "|  0.55|    0.44|  0.15|     0.8945|       0.3145|        0.151|       0.32|        19|    (2,[],[])|\n",
      "+------+--------+------+-----------+-------------+-------------+-----------+----------+-------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "encoded = encoded.drop('Sex')\n",
    "encoded = encoded.drop('NewSex')\n",
    "encoded = encoded.withColumnRenamed('Rings', 'truelabels')\n",
    "encoded.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Split data in 80:20 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total:  4177\n",
      "train:  3388\n",
      "test:  789\n",
      "root\n",
      " |-- Length: double (nullable = true)\n",
      " |-- Diameter: double (nullable = true)\n",
      " |-- Height: double (nullable = true)\n",
      " |-- WholeWeight: double (nullable = true)\n",
      " |-- ShuckedWeight: double (nullable = true)\n",
      " |-- VisceraWeight: double (nullable = true)\n",
      " |-- ShellWeight: double (nullable = true)\n",
      " |-- truelabels: integer (nullable = true)\n",
      " |-- NumericSex: vector (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "(train, test) = encoded.randomSplit([0.8, 0.2])\n",
    "print 'total: ', encoded.count()\n",
    "print 'train: ', train.count()\n",
    "print 'test: ', test.count()\n",
    "train.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Train a Random Forest Regression Model and make predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.regression import RandomForestRegressor\n",
    "from pyspark.ml.feature import VectorIndexer\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "\n",
    "assembler = VectorAssembler(\n",
    "            inputCols = [x for x in encoded.columns if x != 'truelabels'],\n",
    "            outputCol = 'features')\n",
    "\n",
    "rf = RandomForestRegressor(labelCol = 'truelabels', numTrees=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Create pipeline and train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pipeline = Pipeline(stages = [assembler, rf])\n",
    "model = pipeline.fit(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Print top 10 rows of \"predictions\", \"true labels\" and \"features\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+----------+--------------------+\n",
      "|       prediction|truelabels|            features|\n",
      "+-----------------+----------+--------------------+\n",
      "|4.301595486377783|         3|[0.13,0.1,0.03,0....|\n",
      "|4.301595486377783|         4|[0.14,0.105,0.035...|\n",
      "|4.301595486377783|         5|[0.16,0.12,0.035,...|\n",
      "|4.301595486377783|         4|[0.165,0.11,0.02,...|\n",
      "|4.301595486377783|         6|[0.17,0.125,0.055...|\n",
      "|4.353837619244915|         4|[0.175,0.125,0.04...|\n",
      "|4.301595486377783|         4|[0.175,0.125,0.04...|\n",
      "|4.301595486377783|         3|[0.18,0.13,0.045,...|\n",
      "|4.301595486377783|         4|[0.2,0.15,0.04,0....|\n",
      "|4.301595486377783|         4|[0.2,0.155,0.04,0...|\n",
      "+-----------------+----------+--------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions = model.transform(test)\n",
    "predictions.select('prediction', 'truelabels', 'features').show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Evaluate Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root Mean Squared Error:  2.502507697\n",
      "Mean Squared Error:  6.26254477356\n",
      "R-Squared Error:  0.443364702709\n",
      "Mean Absolute Error:  1.73269342845\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "\n",
    "evaluator = RegressionEvaluator(labelCol='truelabels', predictionCol='prediction')\n",
    "\n",
    "# Mean Squared Error\n",
    "rmse = evaluator.evaluate(predictions, {evaluator.metricName:'rmse'})\n",
    "print 'Root Mean Squared Error: ', rmse\n",
    "\n",
    "# Squared Error\n",
    "mse = evaluator.evaluate(predictions, {evaluator.metricName:'mse'})\n",
    "print 'Mean Squared Error: ', mse\n",
    "\n",
    "# R-Squared Error\n",
    "rsq = evaluator.evaluate(predictions, {evaluator.metricName:\"r2\"})\n",
    "print 'R-Squared Error: ', rsq\n",
    "\n",
    "# Mean Absolute Error\n",
    "mae = evaluator.evaluate(predictions, {evaluator.metricName:\"mae\"})\n",
    "print 'Mean Absolute Error: ', mae\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Train a Random Forest Classification Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "\n",
    "rfc = RandomForestClassifier(labelCol='truelabels', featuresCol='features', numTrees=10)\n",
    "pipeline_rfc = Pipeline(stages = [assembler, rfc])\n",
    "model_rfc = pipeline_rfc.fit(train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Print top 10 rows of \"predictions\", \"true labels\" and \"features\" for RF Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+--------------------+\n",
      "|prediction|truelabels|            features|\n",
      "+----------+----------+--------------------+\n",
      "|       4.0|         3|[0.13,0.1,0.03,0....|\n",
      "|       4.0|         4|[0.14,0.105,0.035...|\n",
      "|       4.0|         5|[0.16,0.12,0.035,...|\n",
      "|       4.0|         4|[0.165,0.11,0.02,...|\n",
      "|       4.0|         6|[0.17,0.125,0.055...|\n",
      "|       5.0|         4|[0.175,0.125,0.04...|\n",
      "|       4.0|         4|[0.175,0.125,0.04...|\n",
      "|       4.0|         3|[0.18,0.13,0.045,...|\n",
      "|       4.0|         4|[0.2,0.15,0.04,0....|\n",
      "|       4.0|         4|[0.2,0.155,0.04,0...|\n",
      "+----------+----------+--------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions_rfc = model_rfc.transform(test)\n",
    "predictions_rfc.select('prediction', 'truelabels', 'features').show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Evaluate Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.247148288973\n",
      "Weighted Precision:  0.193466730316\n",
      "Weighted Recall:  0.247148288973\n",
      "Mean Absolute Error:  1.73269342845\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol='truelabels', predictionCol='prediction')\n",
    "\n",
    "# Accuracy\n",
    "accuracy = evaluator.evaluate(predictions_rfc, {evaluator.metricName:'accuracy'})\n",
    "print 'Accuracy: ', accuracy\n",
    "\n",
    "# Weighted Precision\n",
    "weighted_precision = evaluator.evaluate(predictions_rfc, {evaluator.metricName:'weightedPrecision'})\n",
    "print 'Weighted Precision: ', weighted_precision\n",
    "\n",
    "# Weighted Recall\n",
    "weighted_recall = evaluator.evaluate(predictions_rfc, {evaluator.metricName:'weightedRecall'})\n",
    "print 'Weighted Recall: ', weighted_recall\n",
    "\n",
    "# F1\n",
    "f1 = evaluator.evaluate(predictions_rfc, {evaluator.metricName:'f1'})\n",
    "print 'Mean Absolute Error: ', mae\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13. Observations and Conclusion about the metrics and the two models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above two metric evaluation we can conclude that both of them models did not perform well for the given dataset.\n",
    "The results without feature engineering are not enough to compare the models properly as the error(MSE) for Regression model is 6.26 while accuracy for Classification model is 0.24.\n",
    "Difference between two models:\n",
    "Splitting Criteria for both the models is different but depends on the algorithm used.\n",
    "\n",
    "As per the link: http://www.math.usu.edu/adele/RandomForests/Ovronnaz.pdf\n",
    "<br>\n",
    "RF Regression: For regression the predicted value at a node is the average response variable for all observations in the node. This model is used when the predictions are continuous values. This model uses variance as the splitting factor or residual sum of squares. Based on the maximum variance value the nodes are splitted in this model.\n",
    "<br>\n",
    "RF Classifier: For classification the predicted class is the most common class in the node (majority vote). This model is used when the predictions are discrete values. This model uses information gain or Gini criterion for splitting the nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
